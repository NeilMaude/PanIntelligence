{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PanAnalysis Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules\n",
    "\n",
    "Import the modules required for this solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from cached data...\n"
     ]
    }
   ],
   "source": [
    "# Database connection data - may or may not be used...\n",
    "s_server = '169.254.250.189\\SQLEXPRESS' \n",
    "s_database = 'PanAnalysis'\n",
    "s_user = 'sa'\n",
    "s_password = 'Demo'\n",
    "s_connection = 'DRIVER={SQL Server Native Client 11.0};' \n",
    "s_connection += 'SERVER=' + s_server + ';DATABASE=' + s_database +';'\n",
    "s_connection += 'UID=' + s_user +';PWD=' + s_password\n",
    "\n",
    "s_savefile = 'pan_data.pkl'\n",
    "\n",
    "# Read in the data set to a data frame\n",
    "if not os.path.exists(s_savefile):\n",
    "    # Read from the database\n",
    "    print('Reading from live database...')\n",
    "    dbconn = pyodbc.connect(s_connection)\n",
    "    print('Database connection made...')\n",
    "    s_tmpsql = 'select * from zTempPanAnalysis'\n",
    "    df_initial = pd.read_sql_query(s_tmpsql, dbconn)\n",
    "    # Now save it out for later\n",
    "    df_initial.to_pickle(s_savefile)\n",
    "else:\n",
    "    # We have read the data before, so can pull this in from a pickle file\n",
    "    print('Reading from cached data...')\n",
    "    df_initial = pd.read_pickle(s_savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Incident</th>\n",
       "      <th>IncidentType</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>LedgerCode</th>\n",
       "      <th>BusinessType</th>\n",
       "      <th>SiteId</th>\n",
       "      <th>MachinesOnSite</th>\n",
       "      <th>SoleMachine</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>...</th>\n",
       "      <th>AttendOnSite</th>\n",
       "      <th>AttendTimeValid</th>\n",
       "      <th>CallMinutes</th>\n",
       "      <th>MinutesToAttend</th>\n",
       "      <th>MinutesToAttendValid</th>\n",
       "      <th>PostCodeArea</th>\n",
       "      <th>FirstEngineer</th>\n",
       "      <th>SymptomCodeId</th>\n",
       "      <th>SymptomDescription</th>\n",
       "      <th>Repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>145001</td>\n",
       "      <td>BREAKDOWN</td>\n",
       "      <td>12473</td>\n",
       "      <td>S798</td>\n",
       "      <td>Education - Junior/Primary school</td>\n",
       "      <td>21019</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "      <td>769</td>\n",
       "      <td>True</td>\n",
       "      <td>DE23</td>\n",
       "      <td>BEN</td>\n",
       "      <td>S44</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>145002</td>\n",
       "      <td>BREAKDOWN</td>\n",
       "      <td>11546</td>\n",
       "      <td>F119</td>\n",
       "      <td>Education - Junior/Primary school</td>\n",
       "      <td>20497</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>161</td>\n",
       "      <td>814</td>\n",
       "      <td>True</td>\n",
       "      <td>BD10</td>\n",
       "      <td>SERING</td>\n",
       "      <td>S44</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>145004</td>\n",
       "      <td>BREAKDOWN</td>\n",
       "      <td>10751</td>\n",
       "      <td>BS036</td>\n",
       "      <td>Education - Junior/Primary school</td>\n",
       "      <td>23322</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>688</td>\n",
       "      <td>True</td>\n",
       "      <td>BD13</td>\n",
       "      <td>RONNIE</td>\n",
       "      <td>S44</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Incident IncidentType CustomerId LedgerCode  \\\n",
       "0   1   145001    BREAKDOWN      12473       S798   \n",
       "1   2   145002    BREAKDOWN      11546       F119   \n",
       "2   4   145004    BREAKDOWN      10751      BS036   \n",
       "\n",
       "                        BusinessType SiteId  MachinesOnSite  SoleMachine  \\\n",
       "0  Education - Junior/Primary school  21019               4        False   \n",
       "1  Education - Junior/Primary school  20497               1         True   \n",
       "2  Education - Junior/Primary school  23322               2        False   \n",
       "\n",
       "  Manufacturer   ...   AttendOnSite AttendTimeValid CallMinutes  \\\n",
       "0      TOSHIBA   ...           True            True          52   \n",
       "1      TOSHIBA   ...           True            True         161   \n",
       "2      TOSHIBA   ...           True            True          70   \n",
       "\n",
       "   MinutesToAttend  MinutesToAttendValid PostCodeArea  FirstEngineer  \\\n",
       "0              769                  True         DE23            BEN   \n",
       "1              814                  True         BD10         SERING   \n",
       "2              688                  True         BD13         RONNIE   \n",
       "\n",
       "   SymptomCodeId SymptomDescription  Repeat  \n",
       "0            S44       Connectivity   False  \n",
       "1            S44       Connectivity   False  \n",
       "2            S44       Connectivity   False  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check we have this OK\n",
    "df_initial[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape the data ready for model building\n",
    "We will need:\n",
    "- Categorical values to be one-hot encoded - this is for decision tree work and deep learning\n",
    "- Scaling and normalisation of scalar quantities - this is for deep learning only\n",
    "\n",
    "Objective is to produce a data frame for decision trees and a data frame for deep learning.\n",
    "\n",
    "The data frame for deep learning may require data augmentation to balance the training set (REPEATS / non-REPEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree data frame\n",
    "Prepare a data frame for the decision tree work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the main data frame\n",
    "df_tree = df_initial.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoricals to encode are:\n",
    "- Business type\n",
    "- Manufacturer\n",
    "- Product Id (this is going to generate a *lot* of columns)\n",
    "- Device Type\n",
    "- LastOtherCallType\n",
    "- CreatedBy (lots)\n",
    "- PostCodeArea (another large set)\n",
    "- FirstEngineer\n",
    "- SymptomCodeId (lots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for engineers\n",
    "one_hot = pd.get_dummies(df_tree['BusinessType'])\n",
    "print(one_hot[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the join to augment the data frame\n",
    "df_tree = df_tree.join(one_hot)\n",
    "df_tree[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same process for each of the fields we want to one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the target value for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_repeat = df_tree['IncidentType'].map(lambda x: x == 'REPEAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show a few values - there will be few 'True' values as REPEATS are sparse\n",
    "print(df_tree['IncidentType'][0:5])\n",
    "print(y_repeat[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now drop off fields which are not going to be used in the model process.\n",
    "\n",
    "Drop the field which have been one-hot encoded.\n",
    "\n",
    "Fields which are not useful and can also be dropped are:\n",
    "- ID\n",
    "- Incident (incident code)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tree.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Below here is nurdling...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple database query test\n",
    "s_tmpsql = 'select top 10 * from zTempPanAnalysis'\n",
    "dbcursor = dbconn.cursor()\n",
    "dbcursor.execute(s_tmpsql)\n",
    "dbrecordset = dbcursor.fetchall()\n",
    "for record in dbrecordset:\n",
    "    print('Incident ID :', record.Incident)\n",
    "\n",
    "print('\\nShould have printed 10 6-digit incident IDs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = []\n",
    "for record in dbrecordset:\n",
    "    data_array += [[record.Incident, record.IncidentType, record.CustomerId]]\n",
    "print('Data array looks like:\\n')\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_array, columns=['Incident','IncidentType','CustomerId'])\n",
    "print('Data frame looks like:\\n')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns from the recordset\n",
    "s_cols = [col[0] for col in dbcursor.description]\n",
    "print('Columns list:\\n', s_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should fetch some rows and give the sensible column names\n",
    "s_tmpsql2 = 'select top 10 * from zTempPanAnalysis'\n",
    "df2 = pd.read_sql_query(s_tmpsql2, dbconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can now mess about with the dataframe\n",
    "y = df['IncidentType']\n",
    "print('Extracted:\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2\n",
    "del data['IncidentType']\n",
    "print('Feature data:\\n',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_repeat = y.map(lambda x: x == 'REPEAT')\n",
    "print(y_repeat)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times = df2[['AttendHour','CallMinutes','MinutesToAttend']].copy()\n",
    "print (df_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build a decision tree classifier on this data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(df_times,y_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: had to install this new package\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run on the whole dataset\n",
    "# load in the data\n",
    "s_tmpsql_all = 'select * from zTempPanAnalysis'\n",
    "data_all = pd.read_sql_query(s_tmpsql_all, dbconn)\n",
    "# get the repeats\n",
    "y_all = data_all['IncidentType']\n",
    "# get rid of the data not required\n",
    "del data_all['IncidentType']\n",
    "# encode the repeat data for predicion\n",
    "y_repeat_all = y_all.map(lambda x: x == 'REPEAT')\n",
    "# copy out the data we want\n",
    "df_times_all = data_all[['AttendHour','CallMinutes','MinutesToAttend']].copy()\n",
    "# replace any remaining NaN values with -1, to avoid breaking the algorithm\n",
    "df_times_all = df_times_all.fillna(-1)\n",
    "#print (df_times_all)\n",
    "# fit a classifier\n",
    "dtree_all=DecisionTreeClassifier(min_samples_split=500, max_depth=5)\n",
    "dtree_all.fit(df_times_all,y_repeat_all)\n",
    "# visualise\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtree_all, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_times_all[0:10]\n",
    "print(dtree_all.decision_path(df_times_all[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to do some management of the data - e.g. categoricals to IDs etc\n",
    "\n",
    "1. Convert categorical data to IDs - e.g. engineer names, postcodes - consider if one-hot encoding is better here\n",
    "2. Remove fields we don't need - e.g. redundant datatime values, incident IDs, serial numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the distinct values in a categorical column\n",
    "df_categorical = data_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical['BusinessType'] = df_categorical['BusinessType'].astype('category')\n",
    "df_categorical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical['BusinessType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new column with a categorical ID generated from the existing categorical column\n",
    "df_categorical['BusinessType_Categorical'] = df_categorical['BusinessType'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical['BusinessType']\n",
    "df_categorical['BusinessType_Categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for engineers\n",
    "one_hot = pd.get_dummies(data_all['FirstEngineer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now join the one-hot encoded columns to the main dataframe\n",
    "df_coded = df_categorical.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
