{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PanAnalysis Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules\n",
    "\n",
    "Import the modules required for this solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection made...\n"
     ]
    }
   ],
   "source": [
    "s_server = '169.254.250.189\\SQLEXPRESS'\n",
    "s_database = 'PanAnalysis'\n",
    "s_user = 'sa'\n",
    "s_password = 'Demo'\n",
    "\n",
    "s_connection = 'DRIVER={SQL Server Native Client 11.0};' \n",
    "s_connection += 'SERVER=' + s_server + ';DATABASE=' + s_database +';'\n",
    "s_connection += 'UID=' + s_user +';PWD=' + s_password\n",
    "\n",
    "dbconn = pyodbc.connect(s_connection)\n",
    "\n",
    "print('Database connection made...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident ID : 155059\n",
      "Incident ID : 155060\n",
      "Incident ID : 155061\n",
      "Incident ID : 155063\n",
      "Incident ID : 155065\n",
      "Incident ID : 155066\n",
      "Incident ID : 155067\n",
      "Incident ID : 155068\n",
      "Incident ID : 155069\n",
      "Incident ID : 155070\n",
      "\n",
      "Should have printed 10 6-digit incident IDs.\n"
     ]
    }
   ],
   "source": [
    "# Simple database query test\n",
    "s_tmpsql = 'select top 10 * from zTempPanAnalysis'\n",
    "dbcursor = dbconn.cursor()\n",
    "dbcursor.execute(s_tmpsql)\n",
    "dbrecordset = dbcursor.fetchall()\n",
    "for record in dbrecordset:\n",
    "    print('Incident ID :', record.Incident)\n",
    "\n",
    "print('\\nShould have printed 10 6-digit incident IDs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array looks like:\n",
      "\n",
      "[['155059', 'BREAKDOWN', '10023'], ['155060', 'RTF', '12421'], ['155061', 'BREAKDOWN', '12190'], ['155063', 'BREAKDOWN', '11946'], ['155065', 'BREAKDOWN', '12571'], ['155066', 'BREAKDOWN', '10879'], ['155067', 'BREAKDOWN', '11668'], ['155068', 'REPEAT', '13051'], ['155069', 'BREAKDOWN', '11042'], ['155070', 'RTF', '12046']]\n"
     ]
    }
   ],
   "source": [
    "data_array = []\n",
    "for record in dbrecordset:\n",
    "    data_array += [[record.Incident, record.IncidentType, record.CustomerId]]\n",
    "print('Data array looks like:\\n')\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame looks like:\n",
      "\n",
      "  Incident IncidentType CustomerId\n",
      "0   155059    BREAKDOWN      10023\n",
      "1   155060          RTF      12421\n",
      "2   155061    BREAKDOWN      12190\n",
      "3   155063    BREAKDOWN      11946\n",
      "4   155065    BREAKDOWN      12571\n",
      "5   155066    BREAKDOWN      10879\n",
      "6   155067    BREAKDOWN      11668\n",
      "7   155068       REPEAT      13051\n",
      "8   155069    BREAKDOWN      11042\n",
      "9   155070          RTF      12046\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data_array, columns=['Incident','IncidentType','CustomerId'])\n",
    "print('Data frame looks like:\\n')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns list:\n",
      " ['ID', 'Incident', 'IncidentType', 'CustomerId', 'LedgerCode', 'BusinessType', 'SiteId', 'MachinesOnSite', 'SoleMachine', 'Manufacturer', 'SerialNo', 'ProductId', 'DeviceType', 'Colour', 'AncilliariesCount', 'FirstUsed', 'FirstUsedDays', 'Installed', 'InstalledDays', 'PreviousBreakdowns', 'LastBreakCall', 'LastBreakCallDays', 'LastOtherCall', 'LastOtherCallDays', 'LastOtherCallType', 'InitialMeterValueBlack', 'InitialMeterValueColour', 'InitialMeterReadingDate', 'LastMeterValueBlack', 'LastMeterValueColour', 'LastMeterReadingDate', 'BlackClickPerDay', 'ColourClickPerDay', 'TotalClickPerDay', 'CreatedBy', 'CreatedDateTime', 'CreatedTime', 'CreatedDay', 'AttendDateTime', 'AttendDay', 'AttendHour', 'CallMinutes', 'MinutesToAttend', 'PostCodeArea', 'FirstEngineer']\n"
     ]
    }
   ],
   "source": [
    "# Get the columns from the recordset\n",
    "s_cols = [col[0] for col in dbcursor.description]\n",
    "print('Columns list:\\n', s_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should fetch all of the rows and give the sensible column names\n",
    "s_tmpsql2 = 'select top 10 * from zTempPanAnalysis'\n",
    "df2 = pd.read_sql_query(s_tmpsql2, dbconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID Incident IncidentType CustomerId LedgerCode  \\\n",
      "0  1796   155059    BREAKDOWN      10023       M440   \n",
      "1  1797   155060          RTF      12421       T278   \n",
      "2  1798   155061    BREAKDOWN      12190      GP114   \n",
      "3  1799   155063    BREAKDOWN      11946       C614   \n",
      "4  1800   155065    BREAKDOWN      12571       H327   \n",
      "5  1801   155066    BREAKDOWN      10879      MW016   \n",
      "6  1802   155067    BREAKDOWN      11668       N219   \n",
      "7  1803   155068       REPEAT      13051       E226   \n",
      "8  1804   155069    BREAKDOWN      11042      SH067   \n",
      "9  1805   155070          RTF      12046      MR002   \n",
      "\n",
      "                           BusinessType SiteId  MachinesOnSite  SoleMachine  \\\n",
      "0                 Manufacturing - Other  21936               7        False   \n",
      "1     Education - Secondary/High school  23678              16        False   \n",
      "2                   Housing Association  24064              14        False   \n",
      "3     Education - Secondary/High school  20076              14        False   \n",
      "4     Education - Secondary/High school  20904              96        False   \n",
      "5     Education - Secondary/High school  24050              12        False   \n",
      "6     Education - Secondary/High school  22131              15        False   \n",
      "7  Manufacturing - Chemicals/Fuels/Oils  20426               5        False   \n",
      "8     Professional - Architect/Surveyor  20767               4        False   \n",
      "9     Education - Secondary/High school  22516               3        False   \n",
      "\n",
      "  Manufacturer      ...           CreatedDateTime CreatedTime CreatedDay  \\\n",
      "0      TOSHIBA      ...       2017-06-05 09:04:47    09:04:47     Monday   \n",
      "1      TOSHIBA      ...       2017-06-05 09:06:07    09:06:07     Monday   \n",
      "2      TOSHIBA      ...       2017-06-05 09:06:08    09:06:08     Monday   \n",
      "3      TOSHIBA      ...       2017-06-05 09:10:38    09:10:38     Monday   \n",
      "4      TOSHIBA      ...       2017-06-05 09:12:07    09:12:07     Monday   \n",
      "5        RICOH      ...       2017-06-05 09:14:26    09:14:26     Monday   \n",
      "6      TOSHIBA      ...       2017-06-05 09:18:51    09:18:51     Monday   \n",
      "7      TOSHIBA      ...       2017-06-05 09:21:56    09:21:56     Monday   \n",
      "8      TOSHIBA      ...       2017-06-05 09:25:31    09:25:31     Monday   \n",
      "9        XEROX      ...       2017-06-05 09:27:10    09:27:10     Monday   \n",
      "\n",
      "       AttendDateTime  AttendDay AttendHour  CallMinutes MinutesToAttend  \\\n",
      "0 2017-06-05 10:35:00     Monday         10           45              90   \n",
      "1 2017-06-06 08:25:00    Tuesday          8           54             498   \n",
      "2 2017-06-05 10:55:00     Monday         10           25             108   \n",
      "3 2017-06-05 14:23:00     Monday         14           98             312   \n",
      "4 2017-06-05 13:14:00     Monday         13          111             241   \n",
      "5 2017-06-06 09:15:00    Tuesday          9          167             540   \n",
      "6 2017-06-05 10:56:14     Monday         10          206              97   \n",
      "7 2017-06-05 13:12:00     Monday         13           62             230   \n",
      "8 2017-06-05 10:01:59     Monday         10           50              36   \n",
      "9 2017-06-05 11:47:00     Monday         11          143             139   \n",
      "\n",
      "   PostCodeArea  FirstEngineer  \n",
      "0           HX7         DENNIS  \n",
      "1           S65          PAULH  \n",
      "2          CH41          PHILJ  \n",
      "3           WF4          JACOB  \n",
      "4           HG1         DENNIS  \n",
      "5           SK9           TONY  \n",
      "6          TS24        PETERHE  \n",
      "7           HX5         JOHNCR  \n",
      "8           HD6         THOMAS  \n",
      "9           OL9         JOHNST  \n",
      "\n",
      "[10 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted:\n",
      " 0    BREAKDOWN\n",
      "1          RTF\n",
      "2    BREAKDOWN\n",
      "3    BREAKDOWN\n",
      "4    BREAKDOWN\n",
      "5    BREAKDOWN\n",
      "6    BREAKDOWN\n",
      "7       REPEAT\n",
      "8    BREAKDOWN\n",
      "9          RTF\n",
      "Name: IncidentType, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Can now mess about with the dataframe\n",
    "y = df['IncidentType']\n",
    "print('Extracted:\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature data:\n",
      "      ID Incident CustomerId LedgerCode                          BusinessType  \\\n",
      "0  1796   155059      10023       M440                 Manufacturing - Other   \n",
      "1  1797   155060      12421       T278     Education - Secondary/High school   \n",
      "2  1798   155061      12190      GP114                   Housing Association   \n",
      "3  1799   155063      11946       C614     Education - Secondary/High school   \n",
      "4  1800   155065      12571       H327     Education - Secondary/High school   \n",
      "5  1801   155066      10879      MW016     Education - Secondary/High school   \n",
      "6  1802   155067      11668       N219     Education - Secondary/High school   \n",
      "7  1803   155068      13051       E226  Manufacturing - Chemicals/Fuels/Oils   \n",
      "8  1804   155069      11042      SH067     Professional - Architect/Surveyor   \n",
      "9  1805   155070      12046      MR002     Education - Secondary/High school   \n",
      "\n",
      "  SiteId  MachinesOnSite  SoleMachine Manufacturer     SerialNo      ...       \\\n",
      "0  21936               7        False      TOSHIBA    TXJF17539      ...        \n",
      "1  23678              16        False      TOSHIBA    CSEE19360      ...        \n",
      "2  24064              14        False      TOSHIBA    CMD327659      ...        \n",
      "3  20076              14        False      TOSHIBA    CHAG15146      ...        \n",
      "4  20904              96        False      TOSHIBA    C7BD48186      ...        \n",
      "5  24050              12        False        RICOH  W534J400076      ...        \n",
      "6  22131              15        False      TOSHIBA    CFLF37576      ...        \n",
      "7  20426               5        False      TOSHIBA    C7BD46965      ...        \n",
      "8  20767               4        False      TOSHIBA    C7AD42337      ...        \n",
      "9  22516               3        False        XEROX   3909726530      ...        \n",
      "\n",
      "      CreatedDateTime CreatedTime  CreatedDay      AttendDateTime AttendDay  \\\n",
      "0 2017-06-05 09:04:47    09:04:47      Monday 2017-06-05 10:35:00    Monday   \n",
      "1 2017-06-05 09:06:07    09:06:07      Monday 2017-06-06 08:25:00   Tuesday   \n",
      "2 2017-06-05 09:06:08    09:06:08      Monday 2017-06-05 10:55:00    Monday   \n",
      "3 2017-06-05 09:10:38    09:10:38      Monday 2017-06-05 14:23:00    Monday   \n",
      "4 2017-06-05 09:12:07    09:12:07      Monday 2017-06-05 13:14:00    Monday   \n",
      "5 2017-06-05 09:14:26    09:14:26      Monday 2017-06-06 09:15:00   Tuesday   \n",
      "6 2017-06-05 09:18:51    09:18:51      Monday 2017-06-05 10:56:14    Monday   \n",
      "7 2017-06-05 09:21:56    09:21:56      Monday 2017-06-05 13:12:00    Monday   \n",
      "8 2017-06-05 09:25:31    09:25:31      Monday 2017-06-05 10:01:59    Monday   \n",
      "9 2017-06-05 09:27:10    09:27:10      Monday 2017-06-05 11:47:00    Monday   \n",
      "\n",
      "   AttendHour CallMinutes  MinutesToAttend  PostCodeArea FirstEngineer  \n",
      "0          10          45               90           HX7        DENNIS  \n",
      "1           8          54              498           S65         PAULH  \n",
      "2          10          25              108          CH41         PHILJ  \n",
      "3          14          98              312           WF4         JACOB  \n",
      "4          13         111              241           HG1        DENNIS  \n",
      "5           9         167              540           SK9          TONY  \n",
      "6          10         206               97          TS24       PETERHE  \n",
      "7          13          62              230           HX5        JOHNCR  \n",
      "8          10          50               36           HD6        THOMAS  \n",
      "9          11         143              139           OL9        JOHNST  \n",
      "\n",
      "[10 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "data = df2\n",
    "del data['IncidentType']\n",
    "print('Feature data:\\n',data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to do some management of the data - e.g. categoricals to IDs etc\n",
    "\n",
    "1. Convert categorical data to IDs - e.g. engineer names, postcodes - consider if one-hot encoding is better here\n",
    "2. Remove fields we don't need - e.g. redundant datatime values, incident IDs, serial numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'OL9'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-73b91dbe9459>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdtree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FirstEngineer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python35\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'OL9'"
     ]
    }
   ],
   "source": [
    "# Now build a decision tree classifier on this data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "del data['FirstEngineer']\n",
    "dtree.fit(data,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
